{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz5Ls6YUNVi3",
        "outputId": "56eb16ce-8025-4825-9715-fe9778bca1f3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers DataFrame:\n",
            "+-----------+--------------+---------+-----+--------+\n",
            "|Customer_Id|          Name|     City|State|Zip_Code|\n",
            "+-----------+--------------+---------+-----+--------+\n",
            "|      11039|   Mary Torres|   Caguas|   PR|     725|\n",
            "|       5623|    Jose Haley| Columbus|   OH|   43207|\n",
            "|       5829|    Mary Smith|  Houston|   TX|   77015|\n",
            "|       6336|Richard Maddox|   Caguas|   PR|     725|\n",
            "|       1708|Margaret Booth|Arlington|   TX|   76010|\n",
            "+-----------+--------------+---------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Sales Transactions DataFrame:\n",
            "+------------+-----------+----------------+----------+--------------------+------+--------+-----------+\n",
            "|Sales_Txn_Id|Category_Id|   Category_Name|Product_Id|        Product_Name| Price|Quantity|Customer_Id|\n",
            "+------------+-----------+----------------+----------+--------------------+------+--------+-----------+\n",
            "|           1|         43|Camping & Hiking|       957|Diamondback Women...|299.98|       1|      11599|\n",
            "|           2|         48|    Water Sports|      1073|Pelican Sunstream...|199.99|       1|        256|\n",
            "|           3|         24| Women's Apparel|       502|Nike Men's Dri-FI...|  50.0|       5|        256|\n",
            "|           4|         18|  Men's Footwear|       403|Nike Men's CJ Eli...|129.99|       1|        256|\n",
            "|           5|         40|     Accessories|       897|Team Golf New Eng...| 24.99|       2|       8827|\n",
            "+------------+-----------+----------------+----------+--------------------+------+--------+-----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "2025-09-26 05:05:01,062 - INFO - Customers data loaded successfully\n",
            "2025-09-26 05:05:04,212 - INFO - Sales transactions data loaded successfully\n",
            "2025-09-26 05:05:04,282 - INFO - Customers DataFrame:\n",
            "2025-09-26 05:05:04,849 - INFO - Sales Transactions DataFrame:\n"
          ]
        }
      ],
      "source": [
        "#################### Walmart Sales Data Pipeline using Pyspark ##############################\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "import logging\n",
        "\n",
        "\n",
        "# Clean up any existing handlers (important in Colab!)\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "\n",
        "# --- Setup Logging ---\n",
        "log_file = 'walmart.log'\n",
        "logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Creating Spark session\n",
        "spark = SparkSession.builder.appName(\"Walmart Sales Data Pipeline using Pyspark\").getOrCreate()\n",
        "\n",
        "# Loading TSVs into PySpark DataFrames\n",
        "\n",
        "# Trying to load customers tsv file\n",
        "try:\n",
        "  customers_df = spark.read.csv(\"/content/customers.tsv\", sep=\"\\t\", header=False, inferSchema=True)\n",
        "  logging.info(\"Customers data loaded successfully\")\n",
        "except Exception as e:\n",
        "  logging.error(f\"Error loading Customer data: {e}\")\n",
        "\n",
        "# Trying to load sales transactions tsv file\n",
        "try:\n",
        "  salestxns_df = spark.read.csv(\"/content/salestxns.tsv\", sep=\"\\t\", header=False, inferSchema=True)\n",
        "  logging.info(\"Sales transactions data loaded successfully\")\n",
        "except Exception as e:\n",
        "  logging.error(f\"Error loading Sales data: {e}\")\n",
        "\n",
        "# Assign proper column names\n",
        "customers_df = customers_df.toDF(\"Customer_Id\", \"Name\", \"City\", \"State\", \"Zip_Code\")\n",
        "salestxns_df = salestxns_df.toDF(\"Sales_Txn_Id\", \"Category_Id\", \"Category_Name\",\"Product_Id\",\n",
        "                         \"Product_Name\", \"Price\", \"Quantity\", \"Customer_Id\"\n",
        ")\n",
        "\n",
        "# Preview dataframes\n",
        "if customers_df:\n",
        "    logger.info(\"Customers DataFrame:\")\n",
        "    print(\"Customers DataFrame:\")\n",
        "    customers_df.show(5)\n",
        "\n",
        "if salestxns_df:\n",
        "    logger.info(\"Sales Transactions DataFrame:\")\n",
        "    print(\"Sales Transactions DataFrame:\")\n",
        "    salestxns_df.show(5)\n",
        "\n",
        "# --- Show log file contents ---\n",
        "!cat walmart.log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNJ1t2Bog_Sf",
        "outputId": "ac1f8050-b3f2-4c19-c9e0-a27f53a98150",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1244"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salestxns_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SwF2U8OhCiV",
        "outputId": "9dc38bbf-f3a1-4452-f406-146b86b4e026",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172198"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################# Data Cleaning and Transformation#####################\n",
        "\n",
        "# Remove duplicates\n",
        "customers_df = customers_df.dropDuplicates()\n",
        "salestxns_df = salestxns_df.dropDuplicates()\n",
        "logging.info(\"Duplicates removed successfully\")\n",
        "print(\"Duplicates removed successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHUnrsZokezK",
        "outputId": "d32ec7a3-ba8f-4dfd-f54d-26a6a611db92",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicates removed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping null rows\n",
        "customers_df = customers_df.dropna()\n",
        "salestxns_df = salestxns_df.dropna()\n",
        "logging.info(\"Missing values handled successfully\")\n",
        "print(\"Missing values handled successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3800412d-e917-4768-c747-8c433a47ebef",
        "collapsed": true,
        "id": "jyfUCSIyt7mk"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values handled successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the column names to snake-case for consistency\n",
        "customers_df = customers_df.select([col(c).alias(c.lower().replace(' ', '_')) for c in customers_df.columns])\n",
        "salestxns_df = salestxns_df.select([col(c).alias(c.lower().replace(' ', '_')) for c in salestxns_df.columns])\n",
        "\n",
        "logging.info(\"Column names renamed successfully\")\n",
        "print(\"Column names renamed successfully\")\n",
        "\n",
        "customers_df.show(5)\n",
        "salestxns_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Zx1-MMbWuG40",
        "outputId": "507d18a1-8b13-4986-f9c1-114e387c9719"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names renamed successfully\n",
            "+-----------+----------------+-------------+-----+--------+\n",
            "|customer_id|            name|         city|state|zip_code|\n",
            "+-----------+----------------+-------------+-----+--------+\n",
            "|       4234| Dorothy Spencer|      Lilburn|   GA|   30047|\n",
            "|       9272|Ronald Blackwell|       Caguas|   PR|     725|\n",
            "|       8995|      Mary Smith|Mechanicsburg|   PA|   17055|\n",
            "|       7868|   Michael Smith|    Gwynn Oak|   MD|   21207|\n",
            "|       2456|  Joan Donaldson|         York|   PA|   17402|\n",
            "+-----------+----------------+-------------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+------------+-----------+----------------+----------+--------------------+------+--------+-----------+\n",
            "|sales_txn_id|category_id|   category_name|product_id|        product_name| price|quantity|customer_id|\n",
            "+------------+-----------+----------------+----------+--------------------+------+--------+-----------+\n",
            "|         139|         45|         Fishing|      1004|Field & Stream Sp...|399.98|       1|       9213|\n",
            "|         204|         29|   Shop By Sport|       627|Under Armour Girl...| 39.99|       3|       3065|\n",
            "|         331|         26|  Girls' Apparel|       564|Nike Men's Deutsc...|  30.0|       3|      12128|\n",
            "|         453|         43|Camping & Hiking|       957|Diamondback Women...|299.98|       1|       1104|\n",
            "|         616|         18|  Men's Footwear|       403|Nike Men's CJ Eli...|129.99|       1|       9616|\n",
            "+------------+-----------+----------------+----------+--------------------+------+--------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensuring correct data types\n",
        "\n",
        "customers_df = customers_df.withColumn(\"customer_id\", col(\"customer_id\").cast(\"int\"))\n",
        "salestxns_df = salestxns_df.withColumn(\"price\", col(\"price\").cast(\"double\"))\n",
        "salestxns_df = salestxns_df.withColumn(\"quantity\", col(\"quantity\").cast(\"int\"))\n",
        "\n",
        "logging.info(\"Data types ensured successfully\")\n",
        "print(\"Data types ensured successfully\")\n",
        "\n",
        "customers_df.printSchema()\n",
        "salestxns_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bWYJsBXcp5ho",
        "outputId": "bc1290f5-54bc-4976-a608-f776621e2798"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types ensured successfully\n",
            "root\n",
            " |-- customer_id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- zip_code: integer (nullable = true)\n",
            "\n",
            "root\n",
            " |-- sales_txn_id: integer (nullable = true)\n",
            " |-- category_id: integer (nullable = true)\n",
            " |-- category_name: string (nullable = true)\n",
            " |-- product_id: integer (nullable = true)\n",
            " |-- product_name: string (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- quantity: integer (nullable = true)\n",
            " |-- customer_id: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding \"total_amount\" column in sales transaction\n",
        "salestxns_df = salestxns_df.withColumn(\"total_amount\", col(\"price\") * col(\"quantity\"))\n",
        "\n",
        "logging.info(\"Total amount column added successfully\")\n",
        "print(\"Total amount column added successfully\")\n",
        "salestxns_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4tm_v12qscNl",
        "outputId": "3a961930-b8a2-48d1-f7ef-84952d2478a2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total amount column added successfully\n",
            "+------------+-----------+----------------+----------+--------------------+------+--------+-----------+------------+\n",
            "|sales_txn_id|category_id|   category_name|product_id|        product_name| price|quantity|customer_id|total_amount|\n",
            "+------------+-----------+----------------+----------+--------------------+------+--------+-----------+------------+\n",
            "|         139|         45|         Fishing|      1004|Field & Stream Sp...|399.98|       1|       9213|      399.98|\n",
            "|         204|         29|   Shop By Sport|       627|Under Armour Girl...| 39.99|       3|       3065|      119.97|\n",
            "|         331|         26|  Girls' Apparel|       564|Nike Men's Deutsc...|  30.0|       3|      12128|        90.0|\n",
            "|         453|         43|Camping & Hiking|       957|Diamondback Women...|299.98|       1|       1104|      299.98|\n",
            "|         616|         18|  Men's Footwear|       403|Nike Men's CJ Eli...|129.99|       1|       9616|      129.99|\n",
            "+------------+-----------+----------------+----------+--------------------+------+--------+-----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the DataFrames on relevant keys\n",
        "\n",
        "joined_df = salestxns_df.join(customers_df, on=\"customer_id\")\n",
        "joined_df.show(5)\n",
        "\n",
        "logging.info(\"Dataframes joined successfully\")\n",
        "print(\"Dataframes joined successfully\")\n",
        "\n",
        "joined_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RfRPTMoovgv-",
        "outputId": "6779a8a3-5eab-45af-c3b4-1c8a77f5926a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+-----------+----------------+----------+--------------------+-----+--------+------------+-----------+------------+-----+--------+\n",
            "|customer_id|sales_txn_id|category_id|   category_name|product_id|        product_name|price|quantity|total_amount|       name|        city|state|zip_code|\n",
            "+-----------+------------+-----------+----------------+----------+--------------------+-----+--------+------------+-----------+------------+-----+--------+\n",
            "|        409|        1102|         17|          Cleats|       365|Perfect Fitness P...|59.99|       1|       59.99|Kevin Smith|  Greensboro|   NC|   27406|\n",
            "|      10890|        2296|         17|          Cleats|       365|Perfect Fitness P...|59.99|       5|      299.95|Doris Moody|      Caguas|   PR|     725|\n",
            "|      11748|        5591|         29|   Shop By Sport|       627|Under Armour Girl...|39.99|       4|      159.96|James Smith|      Caguas|   PR|     725|\n",
            "|       5013|        6054|         29|   Shop By Sport|       627|Under Armour Girl...|39.99|       2|       79.98|Mary Peters|Reynoldsburg|   OH|   43068|\n",
            "|       7840|        8795|          9|Cardio Equipment|       191|Nike Men's Free 5...|99.99|       1|       99.99| Mary Smith|      Caguas|   PR|     725|\n",
            "+-----------+------------+-----------+----------------+----------+--------------------+-----+--------+------------+-----------+------------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Dataframes joined successfully\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17448"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a temporary view\n",
        "\n",
        "joined_df.createOrReplaceTempView(\"sales_data\")\n",
        "customers_df.createOrReplaceTempView(\"customer_data\")\n",
        "salestxns_df.createOrReplaceTempView(\"sales_trans_data\")\n",
        "logging.info(\"Temporary views created successfully\")\n",
        "print(\"Temporary views created successfully\")\n",
        "result=spark.sql(\"select * from sales_data\")\n",
        "result.show(5)\n",
        "result.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LJ8mLfuaw8S4",
        "outputId": "6e27b359-3eca-4128-ffdf-16e5cb7b1050"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temporary views created successfully\n",
            "+-----------+------------+-----------+----------------+----------+--------------------+-----+--------+------------+-----------+------------+-----+--------+\n",
            "|customer_id|sales_txn_id|category_id|   category_name|product_id|        product_name|price|quantity|total_amount|       name|        city|state|zip_code|\n",
            "+-----------+------------+-----------+----------------+----------+--------------------+-----+--------+------------+-----------+------------+-----+--------+\n",
            "|        409|        1102|         17|          Cleats|       365|Perfect Fitness P...|59.99|       1|       59.99|Kevin Smith|  Greensboro|   NC|   27406|\n",
            "|      10890|        2296|         17|          Cleats|       365|Perfect Fitness P...|59.99|       5|      299.95|Doris Moody|      Caguas|   PR|     725|\n",
            "|      11748|        5591|         29|   Shop By Sport|       627|Under Armour Girl...|39.99|       4|      159.96|James Smith|      Caguas|   PR|     725|\n",
            "|       5013|        6054|         29|   Shop By Sport|       627|Under Armour Girl...|39.99|       2|       79.98|Mary Peters|Reynoldsburg|   OH|   43068|\n",
            "|       7840|        8795|          9|Cardio Equipment|       191|Nike Men's Free 5...|99.99|       1|       99.99| Mary Smith|      Caguas|   PR|     725|\n",
            "+-----------+------------+-----------+----------------+----------+--------------------+-----+--------+------------+-----------+------------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17448"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Total Number of Customers:\n",
        "# How many unique customers are there in the dataset?\n",
        "# Using pyspark\n",
        "result = customers_df.select(\"customer_id\").distinct().count()\n",
        "print(\"Total Number of Customers:\", result)\n",
        "# Using spark sql\n",
        "result =spark.sql(\"select count(distinct(customer_id)) from customer_data\")\n",
        "result .show()\n",
        "logger.info(\"Total Number of Customers calculated successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4G03yFtvc3xi",
        "outputId": "2b9d468c-9a6b-4d97-e3b7-e2adf7ced70f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Customers: 1244\n",
            "+---------------------------+\n",
            "|count(DISTINCT customer_id)|\n",
            "+---------------------------+\n",
            "|                       1244|\n",
            "+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum,round,count,desc,avg,col"
      ],
      "metadata": {
        "id": "UUHFcgpOpRTZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Total Sales by State:\n",
        "# What is the total sales amount for each state?\n",
        "# Using pyspark\n",
        "print(\"Total Sales by State:\")\n",
        "result = joined_df.groupBy(\"state\").agg(round(sum(\"total_amount\"),2).alias(\"total_sales\"))\n",
        "result.show(5)\n",
        "# Using spark sql\n",
        "result= spark.sql(\"select state,round(sum(total_amount),2) as total_sales from sales_data group by state\")\n",
        "result.show(5)\n",
        "logger.info(\"Total Sales by State calculated successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "StpK_9ALk9v4",
        "outputId": "ed4e97ad-fe9e-4bc2-e247-ef0527ecd765"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sales by State:\n",
            "+-----+-----------+\n",
            "|state|total_sales|\n",
            "+-----+-----------+\n",
            "|   AZ|   48702.68|\n",
            "|   SC|    4144.68|\n",
            "|   LA|   24449.42|\n",
            "|   MN|     3549.6|\n",
            "|   NJ|   52303.09|\n",
            "+-----+-----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----+-----------+\n",
            "|state|total_sales|\n",
            "+-----+-----------+\n",
            "|   AZ|   48702.68|\n",
            "|   SC|    4144.68|\n",
            "|   LA|   24449.42|\n",
            "|   MN|     3549.6|\n",
            "|   NJ|   52303.09|\n",
            "+-----+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Top 10 Most Purchased Products:\n",
        "# Which are the top 10 most purchased products based on the quantity sold?\n",
        "# Using Pyspark\n",
        "print(\"Top 10 most purchased products:\")\n",
        "result=salestxns_df.groupBy(\"product_id\",\"product_name\")\\\n",
        "        .agg(sum(\"quantity\").alias(\"total_quantity\"))\\\n",
        "        .orderBy(desc(\"total_quantity\"))\\\n",
        "        .limit(10)\n",
        "result.show(10)\n",
        "# Usingspark sql\n",
        "result=spark.sql(\"select product_id,product_name,sum(quantity) as total_quantity \\\n",
        "                  from sales_trans_data \\\n",
        "                  group by product_id,product_name \\\n",
        "                  order by total_quantity \\\n",
        "                 desc limit 10\")\n",
        "result.show(10)\n",
        "logger.info(\"Top 10 most purchased products calculated successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s-g5Zbt3qSsg",
        "outputId": "e70abded-dd36-4658-b663-e33e69529bf7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 most purchased products:\n",
            "+----------+--------------------+--------------+\n",
            "|product_id|        product_name|total_quantity|\n",
            "+----------+--------------------+--------------+\n",
            "|       365|Perfect Fitness P...|         73698|\n",
            "|       502|Nike Men's Dri-FI...|         62956|\n",
            "|      1014|O'Brien Men's Neo...|         57803|\n",
            "|       191|Nike Men's Free 5...|         36680|\n",
            "|       627|Under Armour Girl...|         31735|\n",
            "|       403|Nike Men's CJ Eli...|         22246|\n",
            "|      1004|Field & Stream Sp...|         17325|\n",
            "|      1073|Pelican Sunstream...|         15500|\n",
            "|       957|Diamondback Women...|         13729|\n",
            "|       977|ENO Atlas Hammock...|           998|\n",
            "+----------+--------------------+--------------+\n",
            "\n",
            "+----------+--------------------+--------------+\n",
            "|product_id|        product_name|total_quantity|\n",
            "+----------+--------------------+--------------+\n",
            "|       365|Perfect Fitness P...|         73698|\n",
            "|       502|Nike Men's Dri-FI...|         62956|\n",
            "|      1014|O'Brien Men's Neo...|         57803|\n",
            "|       191|Nike Men's Free 5...|         36680|\n",
            "|       627|Under Armour Girl...|         31735|\n",
            "|       403|Nike Men's CJ Eli...|         22246|\n",
            "|      1004|Field & Stream Sp...|         17325|\n",
            "|      1073|Pelican Sunstream...|         15500|\n",
            "|       957|Diamondback Women...|         13729|\n",
            "|       977|ENO Atlas Hammock...|           998|\n",
            "+----------+--------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Average Transaction Value:\n",
        "# What is the average price of transactions across all sales?\n",
        "# Using Pyspark\n",
        "print(\"Average Transaction Value:\")\n",
        "result=joined_df.agg(round(avg(col(\"price\")*col(\"quantity\")),2).alias(\"Avg_transaction_value\"))\n",
        "result.show(5)\n",
        "# Using spark sql\n",
        "result=spark.sql(\"select round(avg(price*quantity),2) as Avg_transaction_value from sales_data\")\n",
        "result.show(5)\n",
        "logger.info(\"Average Transaction Value calculated successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Sl5Cfx8X0msV",
        "outputId": "d456b1ab-fcb8-4a8d-ada4-0a6191f25106"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Transaction Value:\n",
            "+---------------------+\n",
            "|Avg_transaction_value|\n",
            "+---------------------+\n",
            "|               198.57|\n",
            "+---------------------+\n",
            "\n",
            "+---------------------+\n",
            "|Avg_transaction_value|\n",
            "+---------------------+\n",
            "|               198.57|\n",
            "+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Top 5 Customers by Expenditure:\n",
        "# Who are the top 5 customers by total amount spent?\n",
        "# Using pyspark\n",
        "print(\"Top 5 Customers by Expenditure:\")\n",
        "result=joined_df.groupBy(\"customer_id\",\"name\")\\\n",
        "        .agg(round(sum(\"total_amount\"),2).alias(\"total_expenditure\"))\\\n",
        "        .orderBy(desc(\"total_expenditure\"))\\\n",
        "        .limit(5)\n",
        "result.show(5)\n",
        "# Using spark sql\n",
        "result=spark.sql(\"select customer_id,name,round(sum(total_amount),2) as total_expenditure \\\n",
        "                  from sales_data \\\n",
        "                  group by customer_id,name \\\n",
        "                  order by total_expenditure \\\n",
        "                  desc limit 5\")\n",
        "result.show(5)\n",
        "logger.info(\"Top 5 Customers by Expenditure calculated successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1TzjOjZ54G2W",
        "outputId": "b853536b-c7bb-4d05-d9d8-7cdf40fc908e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Customers by Expenditure:\n",
            "+-----------+-----------------+-----------------+\n",
            "|customer_id|             name|total_expenditure|\n",
            "+-----------+-----------------+-----------------+\n",
            "|       9371|   Mary Patterson|          9299.03|\n",
            "|        664|    Bobby Jimenez|          8394.26|\n",
            "|      12431|        Mary Rios|          8073.15|\n",
            "|      10591| Deborah Humphrey|          7889.05|\n",
            "|       9271|Christopher Smith|          7665.25|\n",
            "+-----------+-----------------+-----------------+\n",
            "\n",
            "+-----------+-----------------+-----------------+\n",
            "|customer_id|             name|total_expenditure|\n",
            "+-----------+-----------------+-----------------+\n",
            "|       9371|   Mary Patterson|          9299.03|\n",
            "|        664|    Bobby Jimenez|          8394.26|\n",
            "|      12431|        Mary Rios|          8073.15|\n",
            "|      10591| Deborah Humphrey|          7889.05|\n",
            "|       9271|Christopher Smith|          7665.25|\n",
            "+-----------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Product Purchases by a Specific Customer:\n",
        "# List all products purchased by a specific customer (e.g., customer with ID 256),\n",
        "# including the product name, quantity, and total amount spent.\n",
        "\n",
        "# Using pyspark\n",
        "print(\"Product Purchases by a Specific Customer:\")\n",
        "result = (\n",
        "    joined_df.filter(col(\"customer_id\") == 9371)\n",
        "    .withColumn(\"total_amount\", col(\"price\") * col(\"quantity\"))\n",
        "    .groupBy(\"product_id\", \"product_name\")\n",
        "    .agg(\n",
        "        sum(\"quantity\").alias(\"total_quantity\"),\n",
        "        sum(\"total_amount\").alias(\"total_spent\")\n",
        "    )\n",
        "    .orderBy(desc(\"total_spent\"))\n",
        ")\n",
        "\n",
        "result.show(truncate=False)\n",
        "\n",
        "# Using spark sql\n",
        "result = spark.sql(\"select product_id,product_name,\\\n",
        "        sum(quantity) AS total_quantity,\\\n",
        "        sum(price * quantity) AS total_spent\\\n",
        "    from sales_data\\\n",
        "    where customer_id = 9371\\\n",
        "    group by product_id, product_name\\\n",
        "    order by total_spent desc\")\n",
        "result.show()\n",
        "logger.info(\"Product Purchases by a Specific Customer calculated successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yZve58Q06DO1",
        "outputId": "941a311d-e6c6-4b4c-cb4a-0dbcac896f64"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Purchases by a Specific Customer:\n",
            "+----------+---------------------------------------------+--------------+------------------+\n",
            "|product_id|product_name                                 |total_quantity|total_spent       |\n",
            "+----------+---------------------------------------------+--------------+------------------+\n",
            "|1004      |Field & Stream Sportsman 16 Gun Fire Safe    |8             |3199.84           |\n",
            "|365       |Perfect Fitness Perfect Rip Deck             |26            |1559.74           |\n",
            "|957       |Diamondback Women's Serene Classic Comfort Bi|4             |1199.92           |\n",
            "|403       |Nike Men's CJ Elite 2 TD Football Cleat      |6             |779.94            |\n",
            "|1014      |O'Brien Men's Neoprene Life Vest             |14            |699.72            |\n",
            "|502       |Nike Men's Dri-FIT Victory Golf Polo         |9             |450.0             |\n",
            "|1073      |Pelican Sunstream 100 Kayak                  |2             |399.98            |\n",
            "|191       |Nike Men's Free 5.0+ Running Shoe            |4             |399.96            |\n",
            "|728       |LIJA Women's Eyelet Sleeveless Golf Polo     |4             |260.0             |\n",
            "|627       |Under Armour Girls' Toddler Spine Surge Runni|6             |239.94000000000003|\n",
            "|564       |Nike Men's Deutschland Weltmeister Winners Bl|3             |90.0              |\n",
            "|703       |Top Flite Women's 2014 XL Hybrid             |1             |19.99             |\n",
            "+----------+---------------------------------------------+--------------+------------------+\n",
            "\n",
            "+----------+--------------------+--------------+------------------+\n",
            "|product_id|        product_name|total_quantity|       total_spent|\n",
            "+----------+--------------------+--------------+------------------+\n",
            "|      1004|Field & Stream Sp...|             8|           3199.84|\n",
            "|       365|Perfect Fitness P...|            26|           1559.74|\n",
            "|       957|Diamondback Women...|             4|           1199.92|\n",
            "|       403|Nike Men's CJ Eli...|             6|            779.94|\n",
            "|      1014|O'Brien Men's Neo...|            14|            699.72|\n",
            "|       502|Nike Men's Dri-FI...|             9|             450.0|\n",
            "|      1073|Pelican Sunstream...|             2|            399.98|\n",
            "|       191|Nike Men's Free 5...|             4|            399.96|\n",
            "|       728|LIJA Women's Eyel...|             4|             260.0|\n",
            "|       627|Under Armour Girl...|             6|239.94000000000003|\n",
            "|       564|Nike Men's Deutsc...|             3|              90.0|\n",
            "|       703|Top Flite Women's...|             1|             19.99|\n",
            "+----------+--------------------+--------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Monthly Sales Trends:\n",
        "# Assuming there is a date field, analyze the sales trends over the months.\n",
        "# Which month had the highest sales?\n",
        "# Using pyspark\n",
        "print(\"Monthly Sales Trends:\")\n",
        "from pyspark.sql.functions import month\n",
        "\"\"\"monthly_sales = joined_df.groupBy(\"month\") \\\n",
        "                        .agg(sum(\"total_amount\").alias(\"total_sales\")) \\\n",
        "                        .orderBy(desc(\"total_sales\"))\n",
        "\n",
        "# Using spark sql\n",
        "result = spark.sql(\"select MONTH(txn_date) AS month\\\n",
        "                    SUM(price * quantity) AS total_sales\\\n",
        "                    from sales_dtata\\\n",
        "                    group by MONTH(txn_date)\\\n",
        "                    order by total_sales desc\")\"\"\"\n",
        "\n",
        "logger.info(\"Monthly sales trend identified\")"
      ],
      "metadata": {
        "id": "r44upsje_S-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6e0b3a7b-a1bc-43fe-81ed-b4246704fa02"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monthly Sales Trends:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Category with Highest Sales:\n",
        "# Which product category generated the highest total sales revenue?\n",
        "\n",
        "# Using pyspark\n",
        "print(\"Category with Highest Sales:\")\n",
        "category_sales = joined_df.groupBy(\"category_name\") \\\n",
        "                         .agg(round(sum(\"total_amount\"),2).alias(\"total_sales\")) \\\n",
        "                         .orderBy(desc(\"total_sales\"))\n",
        "category_sales.show(1)\n",
        "# Using spark sql\n",
        "category_sales = spark.sql(\"select category_name,\\\n",
        "                    round(SUM(price * quantity),2) AS total_sales\\\n",
        "                    from sales_data\\\n",
        "                    group by category_name\\\n",
        "                    order by total_sales desc\")\n",
        "category_sales.show(1)\n",
        "logger.info(\"Category with highest sales identified\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qu6bWI8pNi9D",
        "outputId": "8490a7c7-0c5c-4401-d0cd-a80dcb421c4b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category with Highest Sales:\n",
            "+-------------+-----------+\n",
            "|category_name|total_sales|\n",
            "+-------------+-----------+\n",
            "|      Fishing|   701964.9|\n",
            "+-------------+-----------+\n",
            "only showing top 1 row\n",
            "\n",
            "+-------------+-----------+\n",
            "|category_name|total_sales|\n",
            "+-------------+-----------+\n",
            "|      Fishing|   701964.9|\n",
            "+-------------+-----------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. State-wise Sales Comparison:\n",
        "# Compare the total sales between two specific states (e.g., Texas vs. Ohio).\n",
        "# Which state had higher sales?\n",
        "# Using pyspark\n",
        "print(\"State-wise Sales Comparison:\")\n",
        "states_to_compare=[\"TX\",\"OH\"]\n",
        "state_sales = joined_df.filter(col(\"state\").isin(states_to_compare))\\\n",
        "                       .groupBy(\"state\") \\\n",
        "                       .agg(round(sum(\"total_amount\"),2).alias(\"total_sales\")) \\\n",
        "                       .orderBy(desc(\"total_sales\"))\n",
        "state_sales.show()\n",
        "# Using spark sql\n",
        "state_sales = spark.sql(\"select state,\\\n",
        "                    round(SUM(price * quantity),2) AS total_sales\\\n",
        "                    from sales_data\\\n",
        "                    where state in ('TX', 'OH')\\\n",
        "                    group by state\\\n",
        "                    order by total_sales desc\")\n",
        "state_sales.show()\n",
        "logger.info(\"State-wise sales comparison identified\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7a-9NkfR2JY",
        "outputId": "e72cef44-9abf-4b20-dd49-36e997100e67",
        "collapsed": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State-wise Sales Comparison:\n",
            "+-----+-----------+\n",
            "|state|total_sales|\n",
            "+-----+-----------+\n",
            "|   TX|   184629.3|\n",
            "|   OH|   82342.95|\n",
            "+-----+-----------+\n",
            "\n",
            "+-----+-----------+\n",
            "|state|total_sales|\n",
            "+-----+-----------+\n",
            "|   TX|   184629.3|\n",
            "|   OH|   82342.95|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Detailed Customer Purchase Report:\n",
        "# Generate a detailed report showing each customer along with their total purchases,\n",
        "# the total number of transactions they have made, and\n",
        "# the average transaction value.\n",
        "# Using pyspark\n",
        "print(\"Detailed Customer Purchase Report:\")\n",
        "customer_report = (joined_df.groupBy(\"customer_id\", \"name\")\n",
        "                   .agg(round(sum(\"total_amount\"),2).alias(\"total_purchases\"),\n",
        "                    count(\"sales_txn_id\").alias(\"num_transactions\"),\n",
        "                    round(avg(\"total_amount\"), 2).alias(\"avg_transaction_value\")\n",
        "                   )\n",
        "                   .orderBy(col(\"total_purchases\").desc())\n",
        "                  )\n",
        "customer_report.show(5)\n",
        "# Using spark sql\n",
        "customer_report = spark.sql(\"select customer_id,name,\\\n",
        "                    round(sum(total_amount),2) AS total_purchases,\\\n",
        "                    count(sales_txn_id) AS num_transactions,\\\n",
        "                    round(avg(total_amount),2) as avg_transaction_value\\\n",
        "                    from sales_data\\\n",
        "                    group by customer_id,name\\\n",
        "                    order by total_purchases desc\")\n",
        "customer_report.show(5)\n",
        "\n",
        "# customer_report.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(\"output/customer_report_csv\")\n",
        "customer_report.toPandas().to_csv(\"customer_report.csv\", index=False)\n",
        "\n",
        "\n",
        "logger.info(\"Customer report created successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PiQIEccBT5DW",
        "outputId": "a9a257f5-a78c-4c3c-96c4-88225b82b6f6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detailed Customer Purchase Report:\n",
            "+-----------+-----------------+---------------+----------------+---------------------+\n",
            "|customer_id|             name|total_purchases|num_transactions|avg_transaction_value|\n",
            "+-----------+-----------------+---------------+----------------+---------------------+\n",
            "|       9371|   Mary Patterson|        9299.03|              44|               211.34|\n",
            "|        664|    Bobby Jimenez|        8394.26|              39|               215.24|\n",
            "|      12431|        Mary Rios|        8073.15|              36|               224.25|\n",
            "|      10591| Deborah Humphrey|        7889.05|              45|               175.31|\n",
            "|       9271|Christopher Smith|        7665.25|              35|               219.01|\n",
            "+-----------+-----------------+---------------+----------------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+-----------------+---------------+----------------+---------------------+\n",
            "|customer_id|             name|total_purchases|num_transactions|avg_transaction_value|\n",
            "+-----------+-----------------+---------------+----------------+---------------------+\n",
            "|       9371|   Mary Patterson|        9299.03|              44|               211.34|\n",
            "|        664|    Bobby Jimenez|        8394.26|              39|               215.24|\n",
            "|      12431|        Mary Rios|        8073.15|              36|               224.25|\n",
            "|      10591| Deborah Humphrey|        7889.05|              45|               175.31|\n",
            "|       9271|Christopher Smith|        7665.25|              35|               219.01|\n",
            "+-----------+-----------------+---------------+----------------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}